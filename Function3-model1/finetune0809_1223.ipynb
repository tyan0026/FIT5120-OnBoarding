{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14388e5d-c073-4a93-bd01-237f0d8e2fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetune Epoch [1/100]  Accuracy: 0.7697\n",
      "Finetune Epoch [2/100]  Accuracy: 0.7610\n",
      "Finetune Epoch [3/100]  Accuracy: 0.7610\n",
      "Finetune Epoch [4/100]  Accuracy: 0.7610\n",
      "Finetune Epoch [5/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [6/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [7/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [8/100]  Accuracy: 0.7522\n",
      "Finetune Epoch [9/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [10/100]  Accuracy: 0.7741\n",
      "Finetune Epoch [11/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [12/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [13/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [14/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [15/100]  Accuracy: 0.7675\n",
      "Finetune Epoch [16/100]  Accuracy: 0.7588\n",
      "Finetune Epoch [17/100]  Accuracy: 0.7522\n",
      "Finetune Epoch [18/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [19/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [20/100]  Accuracy: 0.7522\n",
      "Finetune Epoch [21/100]  Accuracy: 0.7632\n",
      "Finetune Epoch [22/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [23/100]  Accuracy: 0.7632\n",
      "Finetune Epoch [24/100]  Accuracy: 0.7675\n",
      "Finetune Epoch [25/100]  Accuracy: 0.7500\n",
      "Finetune Epoch [26/100]  Accuracy: 0.7632\n",
      "Finetune Epoch [27/100]  Accuracy: 0.7478\n",
      "Finetune Epoch [28/100]  Accuracy: 0.7500\n",
      "Finetune Epoch [29/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [30/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [31/100]  Accuracy: 0.7434\n",
      "Finetune Epoch [32/100]  Accuracy: 0.7478\n",
      "Finetune Epoch [33/100]  Accuracy: 0.7522\n",
      "Finetune Epoch [34/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [35/100]  Accuracy: 0.7566\n",
      "Finetune Epoch [36/100]  Accuracy: 0.7478\n",
      "Finetune Epoch [37/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [38/100]  Accuracy: 0.7544\n",
      "Finetune Epoch [39/100]  Accuracy: 0.7412\n",
      "Finetune Epoch [40/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [41/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [42/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [43/100]  Accuracy: 0.7412\n",
      "Finetune Epoch [44/100]  Accuracy: 0.7412\n",
      "Finetune Epoch [45/100]  Accuracy: 0.7412\n",
      "Finetune Epoch [46/100]  Accuracy: 0.7500\n",
      "Finetune Epoch [47/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [48/100]  Accuracy: 0.7500\n",
      "Finetune Epoch [49/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [50/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [51/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [52/100]  Accuracy: 0.7434\n",
      "Finetune Epoch [53/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [54/100]  Accuracy: 0.7281\n",
      "Finetune Epoch [55/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [56/100]  Accuracy: 0.7434\n",
      "Finetune Epoch [57/100]  Accuracy: 0.7390\n",
      "Finetune Epoch [58/100]  Accuracy: 0.7434\n",
      "Finetune Epoch [59/100]  Accuracy: 0.7500\n",
      "Finetune Epoch [60/100]  Accuracy: 0.7303\n",
      "Finetune Epoch [61/100]  Accuracy: 0.7281\n",
      "Finetune Epoch [62/100]  Accuracy: 0.7412\n",
      "Finetune Epoch [63/100]  Accuracy: 0.7456\n",
      "Finetune Epoch [64/100]  Accuracy: 0.7390\n",
      "Finetune Epoch [65/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [66/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [67/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [68/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [69/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [70/100]  Accuracy: 0.7434\n",
      "Finetune Epoch [71/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [72/100]  Accuracy: 0.7281\n",
      "Finetune Epoch [73/100]  Accuracy: 0.7193\n",
      "Finetune Epoch [74/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [75/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [76/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [77/100]  Accuracy: 0.7259\n",
      "Finetune Epoch [78/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [79/100]  Accuracy: 0.7390\n",
      "Finetune Epoch [80/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [81/100]  Accuracy: 0.7281\n",
      "Finetune Epoch [82/100]  Accuracy: 0.7259\n",
      "Finetune Epoch [83/100]  Accuracy: 0.7237\n",
      "Finetune Epoch [84/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [85/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [86/100]  Accuracy: 0.7368\n",
      "Finetune Epoch [87/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [88/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [89/100]  Accuracy: 0.7325\n",
      "Finetune Epoch [90/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [91/100]  Accuracy: 0.7237\n",
      "Finetune Epoch [92/100]  Accuracy: 0.7259\n",
      "Finetune Epoch [93/100]  Accuracy: 0.7215\n",
      "Finetune Epoch [94/100]  Accuracy: 0.7303\n",
      "Finetune Epoch [95/100]  Accuracy: 0.7303\n",
      "Finetune Epoch [96/100]  Accuracy: 0.7237\n",
      "Finetune Epoch [97/100]  Accuracy: 0.7346\n",
      "Finetune Epoch [98/100]  Accuracy: 0.7237\n",
      "Finetune Epoch [99/100]  Accuracy: 0.7390\n",
      "Finetune Epoch [100/100]  Accuracy: 0.7149\n",
      "Recommended vacant parking spaces： [0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import BallTree\n",
    "import joblib\n",
    "\n",
    "# ==== 1. 数据集类 ====\n",
    "class ParkingDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder, scaler):\n",
    "        self.df = df.copy()\n",
    "        \n",
    "        self.df[\"Status_Timestamp\"] = pd.to_datetime(self.df[\"Status_Timestamp\"], errors='coerce')\n",
    "        self.df[\"hour\"] = self.df[\"Status_Timestamp\"].dt.hour\n",
    "        self.df[\"dayofweek\"] = self.df[\"Status_Timestamp\"].dt.dayofweek\n",
    "        \n",
    "        self.df[[\"lat\", \"lon\"]] = self.df[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "        \n",
    "        self.df[\"Zone_Number\"] = self.df[\"Zone_Number\"].fillna(\"unknown\").astype(str)\n",
    "        self.df[\"Zone_Number_enc\"] = label_encoder.transform(self.df[\"Zone_Number\"])\n",
    "        \n",
    "        self.df[\"is_free\"] = (self.df[\"Status_Description\"].str.lower() == \"unoccupied\").astype(int)\n",
    "        \n",
    "        features = [\"hour\", \"dayofweek\", \"Zone_Number_enc\", \"lat\", \"lon\"]\n",
    "        self.X = scaler.transform(self.df[features])\n",
    "        self.y = self.df[\"is_free\"].values.astype(np.float32)\n",
    "        \n",
    "        self.kerbside_id = self.df[\"KerbsideID\"].values\n",
    "        self.latlon = self.df[[\"lat\", \"lon\"]].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "# ==== 2. 模型 ====\n",
    "class ParkingModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ParkingModel, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "                nn.Linear(input_dim, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "# ==== 3. 读取和预处理数据 ====\n",
    "df = pd.read_csv(\"/Users/sharm/Desktop/FIT5120-OnBoarding/commute_planner/on-street-parking-bay-sensors.csv\")\n",
    "\n",
    "df[\"Status_Timestamp\"] = df[\"Status_Timestamp\"].astype(str).str.strip()\n",
    "df[\"Status_Timestamp\"] = pd.to_datetime(\n",
    "    df[\"Status_Timestamp\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "\n",
    "df[\"hour\"] = df[\"Status_Timestamp\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"Status_Timestamp\"].dt.dayofweek\n",
    "\n",
    "df[[\"lat\", \"lon\"]] = df[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "df[\"Zone_Number\"] = df[\"Zone_Number\"].fillna(\"unknown\").astype(str)\n",
    "\n",
    "def clean_zone_number(z):\n",
    "    try:\n",
    "        f = float(z)\n",
    "        if f.is_integer():\n",
    "            return str(int(f))\n",
    "        else:\n",
    "            return str(f)\n",
    "    except:\n",
    "        return z\n",
    "\n",
    "df[\"Zone_Number\"] = df[\"Zone_Number\"].apply(clean_zone_number)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Zone_Number_enc\"] = label_encoder.fit_transform(df[\"Zone_Number\"])\n",
    "\n",
    "features = [\"hour\", \"dayofweek\", \"Zone_Number_enc\", \"lat\", \"lon\"]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[features])\n",
    "\n",
    "# ==== 4. 分割数据用于预训练和微调 ====\n",
    "recent_cutoff = df[\"Status_Timestamp\"].max() - pd.DateOffset(months=2)\n",
    "recent_df = df[df[\"Status_Timestamp\"] >= recent_cutoff].copy()\n",
    "pretrain_df = df.copy()\n",
    "\n",
    "# ==== 5. 设备和模型初始化 ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ParkingModel(input_dim=len(features)).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(loader)\n",
    "\n",
    "def compute_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# ==== 6. 预训练阶段 ====\n",
    "train_df_pre, val_df_pre = train_test_split(pretrain_df, test_size=0.2, random_state=42)\n",
    "train_dataset_pre = ParkingDataset(train_df_pre, label_encoder, scaler)\n",
    "val_dataset_pre = ParkingDataset(val_df_pre, label_encoder, scaler)\n",
    "train_loader_pre = DataLoader(train_dataset_pre, batch_size=64, shuffle=True)\n",
    "val_loader_pre = DataLoader(val_dataset_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "#print(\"=== Pretraining on all historical data ===\")\n",
    "pretrain_epochs = 450\n",
    "for epoch in range(pretrain_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader_pre, criterion, optimizer, device)\n",
    "    val_loss = eval_one_epoch(model, val_loader_pre, criterion, device)\n",
    "    #print(f\"Pretrain Epoch [{epoch+1}/{pretrain_epochs}] Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# ==== 7. 微调阶段 ====\n",
    "train_df_fine, val_df_fine = train_test_split(recent_df, test_size=0.2, random_state=42)\n",
    "train_dataset_fine = ParkingDataset(train_df_fine, label_encoder, scaler)\n",
    "val_dataset_fine = ParkingDataset(val_df_fine, label_encoder, scaler)\n",
    "train_loader_fine = DataLoader(train_dataset_fine, batch_size=64, shuffle=True)\n",
    "val_loader_fine = DataLoader(val_dataset_fine, batch_size=64, shuffle=False)\n",
    "\n",
    "#print(\"=== Fine-tuning on recent 2 months data ===\")\n",
    "finetune_epochs = 100\n",
    "for epoch in range(finetune_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader_fine, criterion, optimizer, device)\n",
    "    val_loss = eval_one_epoch(model, val_loader_fine, criterion, device)\n",
    "    val_acc = compute_accuracy(model, val_loader_fine, device)\n",
    "    print(f\"Finetune Epoch [{epoch+1}/{finetune_epochs}]  Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# ==== 8. 保存模型和预处理器 ====\n",
    "torch.save(model.state_dict(), \"parking_model_finetuned.pth\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# ==== 9. 推理函数（保持不变） ====\n",
    "def find_nearby_free_slots(zone_number, current_time, top_k=5, radius_m=500):\n",
    "    model = ParkingModel(input_dim=len(features))\n",
    "    model.load_state_dict(torch.load(\"parking_model_finetuned.pth\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "\n",
    "    label_encoder_loaded = joblib.load(\"label_encoder.pkl\")\n",
    "    scaler_loaded = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "    zone_number_str = str(zone_number)\n",
    "    if zone_number_str not in label_encoder_loaded.classes_:\n",
    "        print(f\"Zone number {zone_number_str} not found in label encoder classes.\")\n",
    "        return [0]\n",
    "\n",
    "    hour = current_time.hour\n",
    "    dayofweek = current_time.weekday()\n",
    "    zone_enc = label_encoder_loaded.transform([zone_number_str])[0]\n",
    "\n",
    "    zone_df = df[df[\"Zone_Number\"] == zone_number_str].copy()\n",
    "    if zone_df.empty:\n",
    "        return [0]\n",
    "\n",
    "    zone_df[\"hour\"] = hour\n",
    "    zone_df[\"dayofweek\"] = dayofweek\n",
    "    zone_df[[\"lat\", \"lon\"]] = zone_df[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "    zone_df[\"Zone_Number_enc\"] = zone_enc\n",
    "\n",
    "    X_zone = scaler_loaded.transform(zone_df[features])\n",
    "    with torch.no_grad():\n",
    "        probs = model(torch.tensor(X_zone, dtype=torch.float32)).numpy().flatten()\n",
    "\n",
    "    free_slots = zone_df[probs > 0.5][[\"KerbsideID\", \"lat\", \"lon\"]]\n",
    "    if free_slots.empty:\n",
    "        return [0]\n",
    "\n",
    "    tree = BallTree(np.radians(free_slots[[\"lat\", \"lon\"]].values), metric='haversine')\n",
    "    query_point = np.radians([[free_slots[\"lat\"].mean(), free_slots[\"lon\"].mean()]])\n",
    "    dist, ind = tree.query(query_point, k=min(top_k, len(free_slots)))\n",
    "    nearby_ids = free_slots.iloc[ind[0]][\"KerbsideID\"].tolist()\n",
    "\n",
    "    return nearby_ids\n",
    "\n",
    "# ==== 10. 测试推理 ====\n",
    "test_result = find_nearby_free_slots(zone_number=7539, current_time=datetime.now())\n",
    "print(\"Recommended vacant parking spaces：\", test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f75c28a-dd0f-435d-9356-874b2305d7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models23/scaler.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"./models23/parking_model_finetuned.pth\")\n",
    "joblib.dump(label_encoder, \"./models23/label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"./models23/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ba95ab-ea4c-4a83-899f-a9614d3f0843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用：\n",
    "#import torch\n",
    "#import joblib\n",
    "\n",
    "# 先创建模型实例（要和训练时的模型结构一样）\n",
    "#model = ParkingModel(input_dim=5)  # 你的特征数是5\n",
    "\n",
    "# 加载模型参数\n",
    "#model.load_state_dict(torch.load(\"./models/parking_model_finetuned.pth\", map_location=\"cpu\"))\n",
    "#model.eval()  # 切换到评估模式\n",
    "\n",
    "# 加载预处理对象\n",
    "#label_encoder = joblib.load(\"./models/label_encoder.pkl\")\n",
    "#scaler = joblib.load(\"./models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de2579-3292-4683-b000-83df92545d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
