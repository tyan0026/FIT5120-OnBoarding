{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c7d1e8-7101-465f-b086-49e666b64e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60435, 60436, 60437, 60424, 60425]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.neighbors import BallTree\n",
    "import joblib\n",
    "\n",
    "# ==== 1. 数据集类 ====\n",
    "class ParkingDataset(Dataset):\n",
    "    def __init__(self, df, label_encoder, scaler):\n",
    "        self.df = df.copy()\n",
    "        \n",
    "        self.df[\"Status_Timestamp\"] = pd.to_datetime(self.df[\"Status_Timestamp\"], errors='coerce')\n",
    "        self.df[\"hour\"] = self.df[\"Status_Timestamp\"].dt.hour\n",
    "        self.df[\"dayofweek\"] = self.df[\"Status_Timestamp\"].dt.dayofweek\n",
    "        \n",
    "        self.df[[\"lat\", \"lon\"]] = self.df[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "        \n",
    "        self.df[\"Zone_Number\"] = self.df[\"Zone_Number\"].fillna(\"unknown\").astype(str)\n",
    "        self.df[\"Zone_Number_enc\"] = label_encoder.transform(self.df[\"Zone_Number\"])\n",
    "        \n",
    "        self.df[\"is_free\"] = (self.df[\"Status_Description\"].str.lower() == \"unoccupied\").astype(int)\n",
    "        \n",
    "        features = [\"hour\", \"dayofweek\", \"Zone_Number_enc\", \"lat\", \"lon\"]\n",
    "        self.X = scaler.transform(self.df[features])\n",
    "        self.y = self.df[\"is_free\"].values.astype(np.float32)\n",
    "        \n",
    "        self.kerbside_id = self.df[\"KerbsideID\"].values\n",
    "        self.latlon = self.df[[\"lat\", \"lon\"]].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "\n",
    "# ==== 2. 模型 ====\n",
    "class ParkingModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ParkingModel, self).__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "                nn.Linear(input_dim, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(128, 256),\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.BatchNorm1d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "        )\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "# ==== 3. 读取和预处理数据 ====\n",
    "df = pd.read_csv(\"/Users/duyixuan/Downloads/on-street-parking-bay-sensors.csv\")\n",
    "\n",
    "df[\"Status_Timestamp\"] = df[\"Status_Timestamp\"].astype(str).str.strip()\n",
    "df[\"Status_Timestamp\"] = pd.to_datetime(\n",
    "    df[\"Status_Timestamp\"], errors=\"coerce\", utc=True).dt.tz_convert(None)\n",
    "\n",
    "df[\"hour\"] = df[\"Status_Timestamp\"].dt.hour\n",
    "df[\"dayofweek\"] = df[\"Status_Timestamp\"].dt.dayofweek\n",
    "\n",
    "df[[\"lat\", \"lon\"]] = df[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "df[\"Zone_Number\"] = df[\"Zone_Number\"].fillna(\"unknown\").astype(str)\n",
    "\n",
    "def clean_zone_number(z):\n",
    "    try:\n",
    "        f = float(z)\n",
    "        if f.is_integer():\n",
    "            return str(int(f))\n",
    "        else:\n",
    "            return str(f)\n",
    "    except:\n",
    "        return z\n",
    "\n",
    "df[\"Zone_Number\"] = df[\"Zone_Number\"].apply(clean_zone_number)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Zone_Number_enc\"] = label_encoder.fit_transform(df[\"Zone_Number\"])\n",
    "\n",
    "features = [\"hour\", \"dayofweek\", \"Zone_Number_enc\", \"lat\", \"lon\"]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[features])\n",
    "\n",
    "# ==== 4. 分割数据用于预训练和微调 ====\n",
    "recent_cutoff = df[\"Status_Timestamp\"].max() - pd.DateOffset(months=2)\n",
    "recent_df = df[df[\"Status_Timestamp\"] >= recent_cutoff].copy()\n",
    "pretrain_df = df.copy()\n",
    "\n",
    "# ==== 5. 设备和模型初始化 ====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ParkingModel(input_dim=len(features)).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "def eval_one_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            val_loss += loss.item()\n",
    "    return val_loss / len(loader)\n",
    "\n",
    "def compute_accuracy(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "            outputs = model(X_batch)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return correct / total\n",
    "\n",
    "# ==== 6. 预训练阶段 ====\n",
    "train_df_pre, val_df_pre = train_test_split(pretrain_df, test_size=0.2, random_state=42)\n",
    "train_dataset_pre = ParkingDataset(train_df_pre, label_encoder, scaler)\n",
    "val_dataset_pre = ParkingDataset(val_df_pre, label_encoder, scaler)\n",
    "train_loader_pre = DataLoader(train_dataset_pre, batch_size=64, shuffle=True)\n",
    "val_loader_pre = DataLoader(val_dataset_pre, batch_size=64, shuffle=False)\n",
    "\n",
    "#print(\"=== Pretraining on all historical data ===\")\n",
    "pretrain_epochs = 500\n",
    "for epoch in range(pretrain_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader_pre, criterion, optimizer, device)\n",
    "    val_loss = eval_one_epoch(model, val_loader_pre, criterion, device)\n",
    "    #print(f\"Pretrain Epoch [{epoch+1}/{pretrain_epochs}] Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# ==== 7. 微调阶段 ====\n",
    "train_df_fine, val_df_fine = train_test_split(recent_df, test_size=0.2, random_state=42)\n",
    "train_dataset_fine = ParkingDataset(train_df_fine, label_encoder, scaler)\n",
    "val_dataset_fine = ParkingDataset(val_df_fine, label_encoder, scaler)\n",
    "train_loader_fine = DataLoader(train_dataset_fine, batch_size=64, shuffle=True)\n",
    "val_loader_fine = DataLoader(val_dataset_fine, batch_size=64, shuffle=False)\n",
    "\n",
    "#print(\"=== Fine-tuning on recent 2 months data ===\")\n",
    "finetune_epochs = 10\n",
    "for epoch in range(finetune_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader_fine, criterion, optimizer, device)\n",
    "    val_loss = eval_one_epoch(model, val_loader_fine, criterion, device)\n",
    "    val_acc = compute_accuracy(model, val_loader_fine, device)\n",
    "    #print(f\"Finetune Epoch [{epoch+1}/{finetune_epochs}]  Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# ==== 8. 保存模型和预处理器 ====\n",
    "torch.save(model.state_dict(), \"parking_model_finetuned.pth\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# ==== 9. 推理函数（按经纬度查询） ====\n",
    "def find_nearby_free_slots_by_location(lat, lon, current_time, top_k=5, radius_m=1000):\n",
    "    # 1. 加载模型和预处理器\n",
    "    model = ParkingModel(input_dim=len(features))\n",
    "    model.load_state_dict(torch.load(\"parking_model_finetuned.pth\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "\n",
    "    label_encoder_loaded = joblib.load(\"label_encoder.pkl\")\n",
    "    scaler_loaded = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "    # 2. 构造时间特征\n",
    "    hour = current_time.hour\n",
    "    dayofweek = current_time.weekday()\n",
    "\n",
    "    # 3. 获取所有停车位的基本信息\n",
    "    all_slots = df.copy()\n",
    "    all_slots[[\"lat\", \"lon\"]] = all_slots[\"Location\"].str.split(\",\", expand=True).astype(float)\n",
    "    all_slots[\"Zone_Number_enc\"] = label_encoder_loaded.transform(all_slots[\"Zone_Number\"])\n",
    "\n",
    "    # 4. 找出半径内的停车位\n",
    "    tree = BallTree(np.radians(all_slots[[\"lat\", \"lon\"]].values), metric='haversine')\n",
    "    query_point = np.radians([[lat, lon]])\n",
    "    ind = tree.query_radius(query_point, r=radius_m / 6371000)  # 半径 m 转换成弧度\n",
    "    if len(ind[0]) == 0:\n",
    "        return [0]\n",
    "\n",
    "    nearby_slots = all_slots.iloc[ind[0]].copy()\n",
    "\n",
    "    # 5. 构造预测输入特征\n",
    "    nearby_slots[\"hour\"] = hour\n",
    "    nearby_slots[\"dayofweek\"] = dayofweek\n",
    "    X_nearby = scaler_loaded.transform(nearby_slots[features])\n",
    "\n",
    "    # 6. 预测空闲概率\n",
    "    with torch.no_grad():\n",
    "        probs = model(torch.tensor(X_nearby, dtype=torch.float32)).numpy().flatten()\n",
    "\n",
    "    free_slots = nearby_slots[probs > 0.5][[\"KerbsideID\", \"lat\", \"lon\"]]\n",
    "    if free_slots.empty:\n",
    "        return [0]\n",
    "\n",
    "    # 7. 按距离排序并返回 top_k\n",
    "    free_tree = BallTree(np.radians(free_slots[[\"lat\", \"lon\"]].values), metric='haversine')\n",
    "    dist, ind = free_tree.query(query_point, k=min(top_k, len(free_slots)))\n",
    "    nearby_ids = free_slots.iloc[ind[0]][\"KerbsideID\"].tolist()\n",
    "\n",
    "    return nearby_ids\n",
    "\n",
    "\n",
    "# ==== 10. 测试推理 ====\n",
    "# 测试：按经纬度 + 时间 查询\n",
    "test_result = find_nearby_free_slots_by_location(\n",
    "    lat=-37.8234, \n",
    "    lon=144.9667, \n",
    "    current_time=datetime.now(), \n",
    "    top_k=5, \n",
    "    radius_m=1000\n",
    ")\n",
    "print(#\"附近空闲停车位：\",\n",
    "      test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba4bd4-8877-425d-bed9-2fc2e07e0b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
